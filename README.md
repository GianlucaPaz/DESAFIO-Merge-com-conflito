# üß† Rede Neural - Classificador de Lixo

> Este reposit√≥rio cont√©m os c√≥digos de **treinamento, avalia√ß√£o e convers√£o** da rede neural usada no aplicativo **RecycleApp**.

> O objetivo do modelo √© **classificar imagens de lixo** em m√∫ltiplas categorias (ex.: garrafa de vidro, copo pl√°stico, papel amassado, etc.), gerando um **arquivo `.tflite` otimizado para rodar localmente no Android**, sem necessidade de internet.

---

## ‚öôÔ∏è Tecnologias utilizadas

- **Linguagem:** Python (3.x)
- **Deep Learning:** TensorFlow 2 / Keras
- **Pr√©-processamento de imagens:** Pillow (PIL)
- **M√©tricas e avalia√ß√£o:** scikit-learn
- **Visualiza√ß√£o:** Matplotlib + Seaborn
- **Outros:**
  - Camadas de aumento de dados (data augmentation) do Keras
  - Callbacks de treinamento (`EarlyStopping`, `ReduceLROnPlateau`)
  - Convers√£o para TensorFlow Lite (`tf.lite.TFLiteConverter`)

---

## üß± Estrutura do projeto

```text
TCC/
‚îú‚îÄ images/
‚îÇ  ‚îú‚îÄ train/                # Conjunto de treino + valida√ß√£o (subpastas por classe)
‚îÇ  ‚îÇ  ‚îú‚îÄ glass_bottle/
‚îÇ  ‚îÇ  ‚îú‚îÄ glass_cup/
‚îÇ  ‚îÇ  ‚îú‚îÄ metal_can/
‚îÇ  ‚îÇ  ‚îú‚îÄ paper_bag/
‚îÇ  ‚îÇ  ‚îú‚îÄ paper_ball/
‚îÇ  ‚îÇ  ‚îú‚îÄ paper_milk_package/
‚îÇ  ‚îÇ  ‚îú‚îÄ paper_package/
‚îÇ  ‚îÇ  ‚îú‚îÄ plastic_bottle/
‚îÇ  ‚îÇ  ‚îú‚îÄ plastic_cup/
‚îÇ  ‚îÇ  ‚îî‚îÄ plastic_transparent_cup/
‚îÇ  ‚îî‚îÄ test/                 # Conjunto de teste (mesmos nomes de pastas/classes)
‚îÇ
‚îú‚îÄ venv/                    # (Opcional) Ambiente virtual Python
‚îÇ
‚îú‚îÄ trainer_final_version.py # Script principal de treinamento da rede neural
‚îú‚îÄ evaluate.py              # Avalia√ß√£o em conjunto de teste + matriz de confus√£o
‚îú‚îÄ resize_images.py         # Utilit√°rio para padronizar tamanho das imagens
‚îú‚îÄ tflite_converter.py      # Convers√£o do modelo Keras (.keras) para TFLite (.tflite)
‚îî‚îÄ trash_classifier_model_finetuned.keras
                            # Modelo treinado salvo em formato Keras
```

Obs.: O dataset n√£o √© versionado no GitHub por quest√µes de tamanho/licen√ßa.
O reposit√≥rio assume que voc√™ j√° tem as pastas images/train e images/test organizadas por classe.

---

## üß™ Pipeline do modelo

A pipeline da rede neural √© dividida em 4 etapas principais:
1. Prepara√ß√£o do dataset
2. Treinamento da CNN com focal loss
3. Avalia√ß√£o em conjunto de teste
4. Convers√£o para TensorFlow Lite (.tflite)


### 1Ô∏è‚É£ Prepara√ß√£o do dataset

O TensorFlow usa a fun√ß√£o image_dataset_from_directory, que espera a seguinte estrutura de pastas:

```text
images/
‚îú‚îÄ train/
‚îÇ  ‚îú‚îÄ classe_1/
‚îÇ  ‚îú‚îÄ classe_2/
‚îÇ  ‚îî‚îÄ ...
‚îî‚îÄ test/
   ‚îú‚îÄ classe_1/
   ‚îú‚îÄ classe_2/
   ‚îî‚îÄ ...
```

Cada subpasta representa uma classe e cont√©m apenas imagens daquele tipo.


#### üîß Padroniza√ß√£o opcional do tamanho das imagens

  O script resize_images.py √© um utilit√°rio que:
  1. Abre todas as imagens da pasta images/train;
  2. Corrige rota√ß√£o com base no EXIF;
  3. Converte para RGB;
  4. Redimensiona mantendo propor√ß√£o (thumbnail);
  5. Faz padding para um tamanho fixo (TARGET_SIZE);
  6. Sobrescreve os arquivos originais.

Trecho central:

```text
DATA_DIR = "images/train"
TARGET_SIZE = (299, 299)

img = Image.open(filepath)
img = ImageOps.exif_transpose(img)
img = img.convert("RGB")
img.thumbnail(TARGET_SIZE, Image.Resampling.LANCZOS)
img_padded = ImageOps.pad(img, TARGET_SIZE, color="white")
img_padded.save(filepath, quality=90)
```

‚ö†Ô∏è No treinamento atual o modelo usa IMAGE_SIZE = (256, 256).
O resize_images.py pode ser ajustado para o mesmo tamanho, se necess√°rio.

---

### 2Ô∏è‚É£ Treinamento da rede neural (trainer_final_version.py)

#### üì• Carregamento do dataset

O script separa automaticamente treino e valida√ß√£o a partir da pasta images/train:

    ```text

    IMAGE_SIZE = (256, 256)
    BATCH_SIZE = 24
    VALIDATION_SPLIT_CF = 0.1  # 10% para valida√ß√£o
    DATA_DIR = "./images/train"

    train_ds = tf.keras.preprocessing.image_dataset_from_directory(
       DATA_DIR,
       validation_split=VALIDATION_SPLIT_CF,
       subset="training",
       seed=123,
       image_size=IMAGE_SIZE,
       batch_size=BATCH_SIZE
    )

    val_ds = tf.keras.preprocessing.image_dataset_from_directory(
       DATA_DIR,
       validation_split=VALIDATION_SPLIT_CF,
       subset="validation",
       seed=123,
       image_size=IMAGE_SIZE,
       batch_size=BATCH_SIZE
    )
    ```

Depois o pipeline √© otimizado com:

- cache() ‚Äì cache em mem√≥ria;
- shuffle() ‚Äì embaralhamento do treino;
- map(..., num_parallel_calls=AUTOTUNE) ‚Äì processamento em m√∫ltiplas threads;
- prefetch(AUTOTUNE) ‚Äì sobreposi√ß√£o de I/O e computa√ß√£o.

#### üéõ Aumento de dados (data augmentation)

Para melhorar a generaliza√ß√£o, o modelo aplica v√°rias transforma√ß√µes aleat√≥rias apenas no treino:

    ```text
    data_augmentation = tf.keras.Sequential([
       layers.RandomFlip("horizontal_and_vertical"),
       layers.RandomRotation(0.2),
       layers.RandomTranslation(0.1, 0.1),
       layers.RandomZoom(0.2),
       layers.RandomContrast(0.2),
       layers.RandomBrightness(0.2),
       layers.GaussianNoise(0.05)
    ])
    ```

#### üß© Arquitetura da CNN

A rede √© uma CNN customizada, com 5 blocos convolucionais e pooling global:

    ```text
    model = models.Sequential([
       data_augmentation,
       layers.Rescaling(1./255, input_shape=(IMAGE_SIZE, 3)),  # Normaliza√ß√£o

       layers.Conv2D(32, (3, 3), activation='relu'),
       layers.BatchNormalization(),
       layers.MaxPooling2D(2, 2),

       layers.Conv2D(64, (3, 3), activation='relu'),
       layers.MaxPooling2D(2, 2),

       layers.Conv2D(128, (3, 3), activation='relu'),
       layers.MaxPooling2D(2, 2),

       layers.Conv2D(256, (3, 3), activation='relu'),
       layers.MaxPooling2D(2, 2),

       layers.Conv2D(512, (3, 3), activation='relu'),
       layers.MaxPooling2D(2, 2),

       layers.GlobalAveragePooling2D(),

       layers.Dense(512, activation='relu',
                    kernel_regularizer=regularizers.l2(1e-4)),
       layers.Dropout(0.4),

       layers.Dense(len(class_names), activation='softmax')
    ])
    ```

Conceitualmente, a entrada √© uma imagem 256√ó256√ó3 (RGB normalizada para [0,1]).

#### üéØ Fun√ß√£o de perda: Focal Loss multiclasse

Em vez da entropia cruzada padr√£o, o projeto usa Focal Loss, mais robusta em cen√°rios com classes desbalanceadas:

    ```text
    def focal_loss_multiclass(y_true, y_pred, alpha=0.25, gamma=3.0):
       num_classes = tf.shape(y_pred)[-1]
       y_true_onehot = tf.one_hot(tf.cast(y_true, tf.int32), depth=num_classes)

       epsilon = tf.keras.backend.epsilon()
       y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)

       pt = tf.reduce_sum(y_true_onehot * y_pred, axis=-1)
       modulating_factor = tf.pow(1. - pt, gamma)
       ce = -tf.math.log(pt)

       if isinstance(alpha, (float, int)):
           alpha_factor = alpha
       else:
           alpha_factor = tf.reduce_sum(y_true_onehot * alpha, axis=-1)

       loss = alpha_factor * modulating_factor * ce
       return tf.reduce_mean(loss)
    ```

O modelo √© compilado com:

    ```text
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4),
        loss=focal_loss_multiclass,
        metrics=['accuracy']
    )

    ```

#### ‚è± Callbacks e treinamento em duas fases

O treinamento √© dividido em duas fases, ambas com Early Stopping e ajuste din√¢mico da taxa de aprendizado:

- EPOCHS_INITIAL = 70 ‚Äì treino principal
- EPOCHS_FINE_TUNE = 35 ‚Äì ajuste fino com LR reduzida

Callbacks principais:

```text
reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=3,
    min_lr=1e-6,
    verbose=1
)

early_stop_initial = EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True
)
```

Ap√≥s a primeira fase, o c√≥digo mant√©m a learning rate atual, recompila o modelo e executa o segundo treinamento com callbacks mais agressivos.

Ao final:

```text
model.save('trash_classifier_model_finetuned.keras')
```

### 3Ô∏è‚É£ Avalia√ß√£o do modelo (evaluate.py)

O script evaluate.py carrega:

- O modelo salvo (trash_classifier_model_finetuned.keras);
- O conjunto de teste em ./images/test/.

```text
IMAGE_SIZE = (256, 256)
BATCH_SIZE = 24
TEST_DIR = './images/test/'

model = tf.keras.models.load_model('trash_classifier_model_finetuned.keras', compile=False)

test_ds = tf.keras.preprocessing.image_dataset_from_directory(
    TEST_DIR,
    image_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    shuffle=False
)
class_names = test_ds.class_names
```

Ele calcula:

- Acur√°cia e log loss por classe
- Acur√°cia, precis√£o, recall e F1-score globais
- Matriz de confus√£o (visualizada via Seaborn)

Trecho principal:

```text
overall_acc = accuracy_score(y_true, y_pred)
overall_prec = precision_score(y_true, y_pred, average='weighted', zero_division=0)
overall_rec = recall_score(y_true, y_pred, average='weighted', zero_division=0)
overall_f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)

cm = confusion_matrix(y_true, y_pred, labels=range(len(class_names)))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names, yticklabels=class_names)
```

### 4Ô∏è‚É£ Convers√£o para TensorFlow Lite (tflite_converter.py)

Por fim, o modelo √© convertido para um `.tflite` otimizado, que √© o formato usado no app Android:

```text
import tensorflow as tf

model = tf.keras.models.load_model('trash_classifier_model_finetuned.keras')

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]

tflite_model = converter.convert()

with open('trash_classifier_model_optimized.tflite', 'wb') as f:
    f.write(tflite_model)
```

tf.lite.Optimize.DEFAULT ativa otimiza√ß√µes padr√£o do TensorFlow Lite (como quantiza√ß√£o de pesos), reduzindo o tamanho do modelo e ajudando no desempenho em dispositivos m√≥veis.

---

## ‚ñ∂Ô∏è Como reproduzir o experimento localmente

### 1. Criar e ativar ambiente virtual (opcional, mas recomendado)

```text
python -m venv venv
# Windows
venv\Scripts\activate
# Linux / macOS
source venv/bin/activate
```

### 2. Instalar depend√™ncias

```text
pip install tensorflow numpy matplotlib seaborn scikit-learn pillow
```

(ou via requirements.txt, se criado)

### 3. Organizar o dataset

- Colocar as imagens em `images/train/<nome_da_classe>/...`
- Colocar o conjunto de teste em `images/test/<nome_da_classe>/...`
- Os nomes das pastas de `train/` e `test/` devem ser id√™nticos.

### 4. (Opcional) Padronizar tamanho das imagens

```text
python resize_images.py
```

### 5. Treinar o modelo

```text
python trainer_final_version.py
```

Ao final, ser√° gerado o arquivo:

```text
trash_classifier_model_finetuned.keras
```

### 6. Avaliar em conjunto de teste

```text
python evaluate.py
```

O script imprime m√©tricas no console e abre a matriz de confus√£o em uma janela gr√°fica.

### 7. Gerar modelo TFLite

```text
python tflite_converter.py
```

Sa√≠da esperada:

```text
trash_classifier_model_optimized.tflite
```

Este √© o arquivo que ser√° usado pelo aplicativo Android (RecycleApp) via Interpreter do TensorFlow Lite.

---

## üîó Integra√ß√£o com o RecycleApp

- O arquivo trash_classifier_model_optimized.tflite √© copiado para a pasta assets/ do app Android.
- No app, uma classe utilit√°ria (TrashClassifier.kt) faz:
1. Carregamento da imagem a partir de uma URI;
2. Redimensionamento para 256√ó256;
3. Convers√£o para ByteBuffer float32;
4. Execu√ß√£o do modelo TFLite;
5. Mapeamento do √≠ndice de classe para o material exibido na interface (Vidro, Papel, Pl√°stico, Metal ou Indefinido).

---

## üë• Equipe

Projeto de rede neural desenvolvido como parte do TCC do curso de Ci√™ncia da Computa√ß√£o ‚Äì Universidade Veiga de Almeida, integrado ao aplicativo m√≥vel RecycleApp.

- Respons√°veis pelo desenvolvimento do modelo de IA
  - Davi Millan Alves
  - Gabriel Mesquita Gusm√£o
